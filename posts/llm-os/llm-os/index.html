<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>The Newest Operating System | Sultan Aloufi ðŸ‡¸ðŸ‡¦</title>
<meta name=keywords content><meta name=description content="If you have been using GPT-4, then you realize how much better it is than the free version. It&rsquo;s not just the model itself that got a lot smarter at answering requests but also the tooling developed around it, like searching the internet to get you up-to-date responses if needed, being able to take files and analyze them, running code and then analyzing the result, and using a calculator for things involving math."><meta name=author content><link rel=canonical href=https://sultan-aloufi.github.io/posts/llm-os/llm-os/><link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://sultan-aloufi.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://sultan-aloufi.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://sultan-aloufi.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://sultan-aloufi.github.io/apple-touch-icon.png><link rel=mask-icon href=https://sultan-aloufi.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="The Newest Operating System"><meta property="og:description" content="If you have been using GPT-4, then you realize how much better it is than the free version. It&rsquo;s not just the model itself that got a lot smarter at answering requests but also the tooling developed around it, like searching the internet to get you up-to-date responses if needed, being able to take files and analyze them, running code and then analyzing the result, and using a calculator for things involving math."><meta property="og:type" content="article"><meta property="og:url" content="https://sultan-aloufi.github.io/posts/llm-os/llm-os/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-01-19T23:09:39-05:00"><meta property="article:modified_time" content="2024-01-19T23:09:39-05:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="The Newest Operating System"><meta name=twitter:description content="If you have been using GPT-4, then you realize how much better it is than the free version. It&rsquo;s not just the model itself that got a lot smarter at answering requests but also the tooling developed around it, like searching the internet to get you up-to-date responses if needed, being able to take files and analyze them, running code and then analyzing the result, and using a calculator for things involving math."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://sultan-aloufi.github.io/posts/"},{"@type":"ListItem","position":3,"name":"The Newest Operating System","item":"https://sultan-aloufi.github.io/posts/llm-os/llm-os/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"The Newest Operating System","name":"The Newest Operating System","description":"If you have been using GPT-4, then you realize how much better it is than the free version. It\u0026rsquo;s not just the model itself that got a lot smarter at answering requests but also the tooling developed around it, like searching the internet to get you up-to-date responses if needed, being able to take files and analyze them, running code and then analyzing the result, and using a calculator for things involving math.","keywords":[],"articleBody":"If you have been using GPT-4, then you realize how much better it is than the free version. Itâ€™s not just the model itself that got a lot smarter at answering requests but also the tooling developed around it, like searching the internet to get you up-to-date responses if needed, being able to take files and analyze them, running code and then analyzing the result, and using a calculator for things involving math. Itâ€™s becoming just like a human would behave when trying to find an answer, just a lot faster. Of course, you have to pay USD $20/month to use it.\nGPT-4 has been out for closer to a year, so a new model, GPT-5 or whatever it will be called, is likely to be released soon as such big models take an insane time and compute resource that companies only train such models once a year.\nTo give you an appreciation of how much time, effort, money, and compute these language models take to train, I will try to explain what it takes to produce a model like GPT-4.\nHigh-level training process for a model like GPT-4: First stage: pre-training (done once a year) Collect 100TB of internet data (low-quality data) crawl the internet, Common Crawl Train a transformer (a type of neural network) on that data likely need 60K GPUs or more (\u003e USD $100m) training takes months and there will be errors and issues trying to manage that many GPUs coherently the goal of the transformer is to just be able to predict the next token Now you have a base model a useless model as it does not understand instructions; it can only complete text. Do this stage once a year as itâ€™s expensive and time-consuming Trying to use this base model will look something like this:\nUser: Who was the first president? AI: The president of the United States is the head of state and head of government of the United States,.... So now you have a trained transformer that can only complete text. Continue training that model but this time, be very picky about the data you train it on.\nSecond stage: fine-tuning (done every week) Collect 100k high-quality ideal Q\u0026A responses contract many experts in many fields to answer these questions correctly and with great precision companies like scala.ai provide such data Continue training the base model from the first stage on this data continue to train the weights of the transformer from stage one takes a day to train Collect 1M high-quality ideal comparisons a comparison is a question but with many qualifying answers (but one is usually the best) contract many experts in many fields to select the best answer for a prompt companies like scala.ai provide such data Train a reward model (RLHF model) on the 1M high-quality ideal comparisons collected the algorithm is to predict which answer is the best Collect 100k prompts (no responses) and continue training the transformer model to predict the next token using the trained reward model to generate tokens that maximize the reward Now you have something like GPT-4 Do this second stage every week Most of the financial and engineering pain and time getting something like GPT-4 (99%) is spent on the first stage.\nObviously, GPT-4 can also take images as input, but how so if itâ€™s only trained on text data? When you input an image, there is another model that is trained to output a detailed caption for that image and then give that to GPT-4. This secret model is only able to take an image and output a caption of that image. It canâ€™t do what GPT-4 does, and itâ€™s a fairly cheap and simple model to train compared to GPT-4.\nWell, GPT-4 can output images as well and how it does that is by using another secret small model that is only trained on taking a prompt and turning it into an image.\nWell, GPT-4 is able to take and output audio as well. There is a secret small model trained to take in voice input and convert it to high-accuracy text; that text is then given to GPT-4 to process, and the output from GPT-4 is then read out loud.\nAlso, donâ€™t forget GPT-4 knows how to use a tool to search the internet when needed. It also knows how to use another tool that can run some code and return the result. These tools are cleverly built around GPT-4, so it all looks very seamless to you.\nAs you can see, this is resembling an operating system and not just â€˜a smart chat assistant.â€™ The GPT-4 model is the most important part and the one that goes through this complex training process. Itâ€™s the CPU of the OS, processing instructions and communicating with IO to carry out tasks. The fun part is not only will the core model get better, but the tools and how they are integrated with the model will too.\nI got influenced by the idea of LLM OS first by non other than Andrej karpathy :-)\n[a slide from Andrej karpathy]\n","wordCount":"849","inLanguage":"en","datePublished":"2024-01-19T23:09:39-05:00","dateModified":"2024-01-19T23:09:39-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://sultan-aloufi.github.io/posts/llm-os/llm-os/"},"publisher":{"@type":"Organization","name":"Sultan Aloufi  ðŸ‡¸ðŸ‡¦","logo":{"@type":"ImageObject","url":"https://sultan-aloufi.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://sultan-aloufi.github.io accesskey=h title="Sultan Aloufi  ðŸ‡¸ðŸ‡¦ (Alt + H)">Sultan Aloufi ðŸ‡¸ðŸ‡¦</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://sultan-aloufi.github.io/posts/ title=posts><span>posts</span></a></li><li><a href=https://sultan-aloufi.github.io/projects title=projects><span>projects</span></a></li><li><a href=https://sultan-aloufi.github.io/aboutme/ title="about me"><span>about me</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://sultan-aloufi.github.io>Home</a>&nbsp;Â»&nbsp;<a href=https://sultan-aloufi.github.io/posts/>Posts</a></div><h1 class=post-title>The Newest Operating System</h1><div class=post-meta>&lt;span title='2024-01-19 23:09:39 -0500 -0500'>January 19, 2024&lt;/span>&amp;nbsp;Â·&amp;nbsp;4 min&amp;nbsp;Â·&amp;nbsp;849 words</div></header><div class=post-content><p>If you have been using GPT-4, then you realize how much better it is than the free version. It&rsquo;s not just the model itself that got a lot smarter at answering requests but also the tooling developed around it, like searching the internet to get you up-to-date responses if needed, being able to take files and analyze them, running code and then analyzing the result, and using a calculator for things involving math. It&rsquo;s becoming just like a human would behave when trying to find an answer, just a lot faster. Of course, you have to pay USD $20/month to use it.</p><p>GPT-4 has been out for closer to a year, so a new model, GPT-5 or whatever it will be called, is likely to be released soon as such big models take an insane time and compute resource that companies only train such models once a year.</p><p>To give you an appreciation of how much time, effort, money, and compute these language models take to train, I will try to explain what it takes to produce a model like GPT-4.</p><h2 id=high-level-training-process-for-a-model-like-gpt-4>High-level training process for a model like GPT-4:<a hidden class=anchor aria-hidden=true href=#high-level-training-process-for-a-model-like-gpt-4>#</a></h2><h3 id=first-stage-pre-training-done-once-a-year>First stage: pre-training (done once a year)<a hidden class=anchor aria-hidden=true href=#first-stage-pre-training-done-once-a-year>#</a></h3><ul><li>Collect 100TB of internet data (low-quality data)<ul><li>crawl the internet, Common Crawl</li></ul></li><li>Train a transformer (a type of neural network) on that data<ul><li>likely need 60K GPUs or more (> USD $100m)</li><li>training takes months and there will be errors and issues trying to manage that many GPUs coherently</li><li>the goal of the transformer is to just be able to predict the next token</li></ul></li><li>Now you have a base model<ul><li>a useless model as it does not understand instructions; it can only complete text.</li></ul></li><li>Do this stage once a year as it&rsquo;s expensive and time-consuming</li></ul><p>Trying to use this base model will look something like this:</p><pre tabindex=0><code>User: Who was the first president?

AI: The president of the United States is the head of state and head of government of the United States,....
</code></pre><p>So now you have a trained transformer that can only complete text. Continue training that model but this time, be very picky about the data you train it on.</p><h3 id=second-stage-fine-tuning-done-every-week>Second stage: fine-tuning (done every week)<a hidden class=anchor aria-hidden=true href=#second-stage-fine-tuning-done-every-week>#</a></h3><ul><li>Collect 100k high-quality ideal Q&amp;A responses<ul><li>contract many experts in many fields to answer these questions correctly and with great precision</li><li>companies like scala.ai provide such data</li></ul></li><li>Continue training the base model from the first stage on this data<ul><li>continue to train the weights of the transformer from stage one</li><li>takes a day to train</li></ul></li><li>Collect 1M high-quality ideal comparisons<ul><li>a comparison is a question but with many qualifying answers (but one is usually the best)</li><li>contract many experts in many fields to select the best answer for a prompt</li><li>companies like scala.ai provide such data</li></ul></li><li>Train a reward model (RLHF model) on the 1M high-quality ideal comparisons collected<ul><li>the algorithm is to predict which answer is the best</li></ul></li><li>Collect 100k prompts (no responses) and continue training the transformer model to predict the next token using the trained reward model to generate tokens that maximize the reward</li><li>Now you have something like GPT-4</li><li>Do this second stage every week</li></ul><p>Most of the financial and engineering pain and time getting something like GPT-4 (99%) is spent on the first stage.</p><p>Obviously, GPT-4 can also take images as input, but how so if it&rsquo;s only trained on text data? When you input an image, there is another model that is trained to output a detailed caption for that image and then give that to GPT-4. This secret model is only able to take an image and output a caption of that image. It can&rsquo;t do what GPT-4 does, and it&rsquo;s a fairly cheap and simple model to train compared to GPT-4.</p><p>Well, GPT-4 can output images as well and how it does that is by using another secret small model that is only trained on taking a prompt and turning it into an image.</p><p>Well, GPT-4 is able to take and output audio as well. There is a secret small model trained to take in voice input and convert it to high-accuracy text; that text is then given to GPT-4 to process, and the output from GPT-4 is then read out loud.</p><p>Also, don&rsquo;t forget GPT-4 knows how to use a tool to search the internet when needed. It also knows how to use another tool that can run some code and return the result. These tools are cleverly built around GPT-4, so it all looks very seamless to you.</p><p>As you can see, this is resembling an operating system and not just &lsquo;a smart chat assistant.&rsquo; The GPT-4 model is the most important part and the one that goes through this complex training process. It&rsquo;s the CPU of the OS, processing instructions and communicating with IO to carry out tasks. The fun part is not only will the core model get better, but the tools and how they are integrated with the model will too.</p><p>I got influenced by the idea of LLM OS first by non other than Andrej karpathy :-)</p><p><img loading=lazy src=../image.png alt=whyyy title="a slide from Andrej karpathy"></p><p>[a slide from Andrej karpathy]</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=next href=https://sultan-aloufi.github.io/posts/hello/hello/><span class=title>Next Â»</span><br><span>Hooking Demystified</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://sultan-aloufi.github.io>Sultan Aloufi ðŸ‡¸ðŸ‡¦</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>